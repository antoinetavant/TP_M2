{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear systems\n",
    "\n",
    "## Linear equation\n",
    "\n",
    "$$ A \\cdot x  = b$$\n",
    "\n",
    "Is similare to:\n",
    "\n",
    "\\begin{equation}\\label{eq2}\n",
    "   \\begin{bmatrix}\n",
    "    a_{11}       & a_{12} & a_{13} & \\dots & a_{1n} \\\\\n",
    "    a_{21}       & a_{22} & a_{23} & \\dots & a_{2n} \\\\\n",
    "    \\dots & \\dots & \\dots & \\dots & \\dots \\\\\n",
    "    a_{d1}       & a_{d2} & a_{d3} & \\dots & a_{dn}\n",
    "\\end{bmatrix}\\cdot\\begin{bmatrix}\n",
    "    x_{1}  \\\\ x_{2} \\\\ \\dots  \\\\ x_{d}      \n",
    "\\end{bmatrix}\n",
    "    =\\begin{bmatrix}\n",
    "    b_{1}  \\\\ b_{2}  \\\\ \\dots  \\\\ b_{d}      \n",
    "\\end{bmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "The objective is to solve \\ref{eq2} numericaly, the fastest, the more accurately.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different methodes\n",
    "\n",
    "### Gauss elimination\n",
    "Remove the unknown $x_1$ from every equation exept the first by subtracting $m_{j1}=\\frac{a_{j1}}{a_{11}}$ times the first equation.\n",
    "\n",
    "Repeat to the other, until obtaining a triangular system\n",
    "\n",
    "\\begin{equation}\\label{triangulare}\n",
    "   \\begin{bmatrix}\n",
    "    a_{11}  & a_{12} & a_{13} & \\dots & a_{1n} \\\\\n",
    "    0       & a_{22} & a_{23} & \\dots & a_{2n} \\\\\n",
    "    0       & 0      & a_{33} & \\dots & a_{3n} \\\\\n",
    "    \\dots   & \\dots  & \\dots  & \\ddots & \\dots \\\\\n",
    "    0       & 0 & 0  & \\dots  & a_{dn}\n",
    "\\end{bmatrix} \\cdot \\begin{bmatrix}\n",
    "    x_{1}  \\\\ x_{2} \\\\ x_{3}\\\\ \\dots  \\\\ x_{d}      \n",
    "\\end{bmatrix}\n",
    "    =\\begin{bmatrix}\n",
    "    b_{1}  \\\\ b_{2}  \\\\ b_{3}  \\\\ \\dots  \\\\ b_{d}      \n",
    "\\end{bmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "This phase is the **Forward elimination**\n",
    "\n",
    "Then, use the last line to find $x_d$. Use $x_d$ in the line $d-1$ to find $x_{d-1}$, and so one.\n",
    "This phase is the **Backward substitution**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Complexity**\n",
    "\n",
    "We can count the number of calculation needed to perform the Gauss elimination, and we find that approximately $n^3/3$ multiplications and $n^2/2$ divisions are needed\n",
    "\n",
    "**Limitations**\n",
    "* If a diagnoal element is closed to $0$, then the algorithm described do not work. Adding a **Pivoting** step is needed.\n",
    "* If the matrix in _ill-conditioned_ (ie. the solution is highly sensitive to the data), the obtained sollution can be highly affected by numerical issues (roundoff error) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tridiagonal systems**\n",
    "\n",
    "In some case, as for a tridiagnonal system, knowing the matrix structure can lead to improve efficiency.\n",
    "\n",
    "A tridiagnal matrix is _spacs_, that is as only few non-zero ellements. This implise that the matrix can be stored by storing the thre vectors representing these diagonals.\n",
    "\n",
    "\\begin{equation}\\label{tridiagonal}\n",
    "   \\begin{bmatrix}\n",
    "    a_1&b_1&      &       &       &        \\\\\n",
    "    c_2&a_2& b_{2}&       &       &        \\\\\n",
    "       &c_3& a_{3}&b_{3}  &       &        \\\\\n",
    "       &   &\\ddots&\\ddots &\\ddots &        \\\\\n",
    "       &   &      &c_{d-1}&a_{d-1}& b_{d-1}\\\\\n",
    "       &   &      &       &c_d    & a_{d}\n",
    "\\end{bmatrix}\\cdot\\begin{bmatrix}\n",
    "    x_1 \\\\ x_2 \\\\ x_3 \\\\ \\dots \\\\ x_{d-1} \\\\ x_d    \n",
    "\\end{bmatrix}=\\begin{bmatrix}\n",
    "    b_1  \\\\ b_2  \\\\ b_3  \\\\ \\dots \\\\ b_{d-1} \\\\ b_d      \n",
    "\\end{bmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "For such a system, the Gauss elimination can be simplify to performe only $3n$ multiplications and $2n$ divisions. This algorithm is name _Thomas method_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LU Factorisation\n",
    "\n",
    "If we want to solve $A x = b$ muliple times for differents $b$, it can be useful to store the first step of the Gauss ellimination (the coefficents $m_{ij}$), that do not depend of $b$.\n",
    "This results of an **Upper triangulare** matrix $U$ as well of a **Lower triangulare** $L$, so that:\n",
    "$$ A = LU $$\n",
    "\n",
    "Now, to solve $LU x = b$, we first solve $Lz = b$ by _forward substitution_ and then $Ux = z$ by _backward substitution_.\n",
    "\n",
    "\n",
    "The complexity of the factorisation in $\\mathcal{0}(n^3)$ but each solve is in $\\mathcal{0}(n^2)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterative refinement\n",
    "\n",
    "The numerical solution $\\tilde x$ can be affected by the accumulation of roundoff error (especially is the matrix is ill-conditioned).\n",
    "\n",
    "The residual vector is defined by $r = b - A \\tilde x$. If we could solve the system $A y = r$, then $A (\\tilde x + y)=b$, ie $(\\tilde x + y)$ is the _exact_ solution.\n",
    "In practice, we can only find $\\tilde y$ and hope that $\\tilde x + \\tilde y$ is closer to the true solution.\n",
    "\n",
    "This suggests a possible **iterative method**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterative methods\n",
    "Once again, the structure of the matrix can help us improve the efficientcy. By exemple, if the system is spase, iteretive methodes can be better than direct ones.\n",
    "\n",
    "We can always decompose a matrix in $A = D + L + U$, where $D$ is the diagonal matrix, and $L$ and $U$ are a lower and upper triangulare matrixs, respectively. \n",
    "\n",
    "## The Jacobi iteration\n",
    "We generate the next estimation of the solution with\n",
    "\\begin{equation}\\label{eq:jacobi}\n",
    "x^{(k+1)} = D^{-1} \\left[b - (L + U)x^{(k)}   \\right]\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "## The Gauss - Seidel iteration\n",
    "In the iterations of \\ref{eq:jacobi}, we actualy compute $x^{(k+1)}_1$ befor the others. Hence, why not use it to calculate $x^{(k+1)}_1$ ?\n",
    "\n",
    "This is the **Gauss - Seidel** method, that could be written as:\n",
    "\\begin{equation}\\label{eq:GS}\n",
    "x^{(k+1)} = D^{-1} \\left[b - (L x^{(k+1)} + U x^{(k)})   \\right]\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "## Complexity\n",
    "Both methodes have roughly $n^2$ multiplications and $n$ divisions. Hence these method are less computationally less expensive if we can converge in fess than $n/3$ iterations\n",
    "\n",
    "**Parallelizablility**\n",
    "In general, the Gauss-Seidel methode converge faster than the Jacobi. \n",
    "However, the calculations of the Jacobi method can be all done in the same time, while the calculation of the Gauss - Seidel step cannot, as the value of $x^{(k+1)}_1$ is needed to calculated $x^{(k+1)}_2$\n",
    "\n",
    "## Convergence\n",
    "The iterative methode may not converge. The simplest condition under which both iterativ methode converge is when the matrix is _diagonally dominant_ :\n",
    "$$ |a_{ii}| > \\sum_{j \\neq i} |a_{ij}|, \\quad \\forall i $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": false,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
